{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x291fb15cff0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, Features, Value, DatasetDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 6\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset('csv', data_files='dataset/recipes_80k_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    }
   ],
   "source": [
    "# see datatype of df\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': Value(dtype='int64', id=None),\n",
       " 'cooking_method': Value(dtype='string', id=None),\n",
       " 'ingredients': Value(dtype='string', id=None),\n",
       " 'recipe_name': Value(dtype='string', id=None),\n",
       " 'tags': Value(dtype='string', id=None),\n",
       " 'Vegetarian&Desserts': Value(dtype='int64', id=None),\n",
       " 'Vegetarian': Value(dtype='int64', id=None),\n",
       " 'Dairy Free': Value(dtype='int64', id=None),\n",
       " 'Gluten Free': Value(dtype='int64', id=None),\n",
       " 'Low Carb': Value(dtype='int64', id=None),\n",
       " 'Low Fat': Value(dtype='int64', id=None),\n",
       " 'Low Sodium': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first column\n",
    "df['train'] = df['train'].remove_columns('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cooking_method': [\"['Set the racks in the middle and upper thirds of the oven and preheat the oven to 425 F', 'In a large skillet over medium heat, heat the olive oil until shimmering. Add the onion, garlic and red pepper flakes and cook until golden, stirring occasionally, about 5 minutes.', 'Add the fennel and cook until the vegetables are soft and translucent, an additional 3 to 5 minutes.', 'Reduce the heat to medium and add the tomatoes with their juices. Using the back of a wooden spoon, smash the tomatoes and cook for 5 minutes.', 'Add the basil, wine, olives, 1 teaspoon salt, and 1/8 teaspoon black pepper.', 'Reduce to low and simmer for 15 minutes, or until the sauce is slightly thickened, while you prepare the fish.', 'Pat the fillets dry, lightly spray them with cooking spray, and season with salt and pepper.', 'In a heavy ovenproof skillet over high heat, heat the olive oil until shimmering. Add the fillets, rounded-side down, and cook for 2 minutes.', 'Carefully flip the fillets with a metal spatula and place the skillet in the oven. Bake until the fish is no longer translucent, 8 to 10 minutes.', 'Switch the oven to broil and place the skillet on the upper rack. Broil until the tops of the fillets are golden brown, 2 to 4 minutes.', 'Arrange the fillets on individual plates, spoon on the sauce, and serve.']\",\n",
       "  \"['Place the eggs in the air fryer basket and cook 250F 15 minutes for a softer yolk, 17 minutes for a firmer yolk (time may vary depending on the make and model of your air fryer).', 'Run under cold water and peel right away.']\",\n",
       "  \"['Air Fryer directions:', 'Preheat air fryer to 400F. Spritz the basket with olive oil.', 'Season the salmon with lemon juice, salt and pepper.', 'Mix the mayonnaise with basil and 2 tablespoons Parmesan cheese in a small bowl.', 'Spread completely over the top of salmon. Sprinkle remaining Parmesan cheese on top.', 'In batches, air fry 7 minutes, or longer depending on thickness of the salmon.', 'Oven directions:', 'Preheat the oven to 425F. Spritz a sheet pan with olive oil.', 'Season the salmon with lemon juice, salt and pepper.', 'Mix the mayonnaise with basil and 2 tablespoons Parmesan cheese in a small bowl.', 'Spread completely over the top of salmon. Sprinkle remaining Parmesan cheese on top.', 'Bake 10 to 12 minutes, depending on thickness of the salmon.', ' ']\",\n",
       "  \"['Preheat the oven to 400F.', 'Pour 2 tablespoon of grated cheese onto a silicone lined baking sheet (highly recommended for this) and lightly pat down with your fingers to make about 4 inches round.', 'Repeat 3 more times with remaining cheese, leaving 1/2-inch space in between each circle.', 'Bake 3 minutes, until almost done.', 'Combine the sesame seeds, onion, garlic and poppy seeds in a small bowl.', 'Top each with 3/4 teaspoon.', 'Bake for 5 minutes or until golden and crisp. Cool before eating.']\",\n",
       "  \"['Cook potatoes in a large pot of salted water until tender, about 25 to 30 minutes.', 'In a second pot, cover string beans with water and boil until string beans are tender, 6 to 7 minutes. Drain then quickly run under cold water to prevent them from overcooking.', 'When the potatoes are done, drain.', 'In a large bowl, combine balsamic, oil, salt and pepper.', 'Add the potatoes, green beans, scallions and olives. Mix well and serve room temperature.']\"],\n",
       " 'ingredients': [\"['1 tablespoons extra virgin olive oil', '1 cup chopped yellow onion', '3 cloves garlic (minced)', '1/4 teaspoon crushed red pepper flakes (or to taste)', '1/2 cup chopped fennel', 'One 28 ounce can whole peeled tomatoes (with their juices)', '3/4 cup fresh basil leaves (very thinly sliced)', '1/2 cup dry white wine', '1/4 cup pitted Kalamata olives (halved)', 'Kosher salt', 'Freshly ground pepper', 'Four 4-6 ounce skinless Chilean sea bass fillets (or other sustainable firm white-fleshed fish fillets such as halibut, cod or striped bass)', 'Organic olive oil cooking spray', 'Kosher salt', 'Freshly ground black pepper', '1 tablespoon extra-virgin olive oil']\",\n",
       "  \"['4 large eggs', 'Salt (black pepper, everything bagel seasoning, optional)']\",\n",
       "  \"['olive oil spray', '4 about 5 ounce each salmon fillets, skin removed', '1/2 lemon', '1/4 teaspoon Kosher salt', 'freshly ground black pepper', '3 tablespoons mayonnaise (I like Sir Kensington)', '6 fresh basil leaves (minced, plus more for garnish)', '3 tablespoons grated Parmesan or Romano cheese', ';']\",\n",
       "  \"['1/2 cup freshly grated Parmesan (not pre-grated using the large holes of a box grater)', '3/4 teaspoon sesame seeds', '3/4 teaspoon minced dried onion flakes', '3/4 teaspoon minced dried garlic flakes', '3/4 teaspoon poppy seeds']\",\n",
       "  \"['3 1/2 pounds new potatoes (about 10 peeled and cut 1-inch pieces)', '1 lb green beans beans (ends trimmed)', '1 2.25 oz can sliced black olives, drained', '1/4 cup balsamic vinegar', '1/4 cup extra virgin olive oil', '3 scallions (chopped)', '1 teaspoon kosher salt and fresh black pepper']\"],\n",
       " 'recipe_name': ['Mediterranean Sea Bass',\n",
       "  'Air Fryer Hard Boiled Eggs',\n",
       "  'Air Fryer Basil-Parmesan Salmon',\n",
       "  'Everything Parmesan Crisps',\n",
       "  'Potato and Green Bean Salad'],\n",
       " 'tags': ['Dairy Free, Gluten Free, Keto Recipes, Kid Friendly, Low Carb, Under 30 Minutes',\n",
       "  'Air Fryer Recipes, Dairy Free, Gluten Free, Keto Recipes, Kid Friendly, Low Carb, Paleo, Under 30 Minutes, Vegetarian Meals, Whole 30 Recipes',\n",
       "  'Air Fryer Recipes, Gluten Free, Keto Recipes, Kid Friendly, Low Carb, Under 30 Minutes',\n",
       "  'Gluten Free, Keto Recipes, Kid Friendly, Low Carb, Under 30 Minutes, Vegetarian Meals',\n",
       "  'Dairy Free, Gluten Free, Kid Friendly, Vegetarian Meals, Whole 30 Recipes'],\n",
       " 'Vegetarian&Desserts': [0, 1, 0, 1, 1],\n",
       " 'Vegetarian': [0, 1, 0, 1, 1],\n",
       " 'Dairy Free': [1, 1, 0, 0, 1],\n",
       " 'Gluten Free': [1, 1, 1, 1, 1],\n",
       " 'Low Carb': [1, 1, 1, 1, 0],\n",
       " 'Low Fat': [0, 0, 0, 0, 0],\n",
       " 'Low Sodium': [0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 instances of dataset\n",
    "df['train'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Casting\n",
    "As we can see a few cells above, the first 4 features are already in the wanted data type: `string`. Let's cast the others into `bool` (... and make other adjustments). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cooking_method': Value(dtype='string', id=None),\n",
       " 'ingredients': Value(dtype='string', id=None),\n",
       " 'recipe_name': Value(dtype='string', id=None),\n",
       " 'tags': Value(dtype='string', id=None),\n",
       " 'Vegetarian&Desserts': Value(dtype='int64', id=None),\n",
       " 'Dairy Free': Value(dtype='int64', id=None),\n",
       " 'Gluten Free': Value(dtype='int64', id=None),\n",
       " 'Low Carb': Value(dtype='int64', id=None),\n",
       " 'Low Fat': Value(dtype='int64', id=None),\n",
       " 'Low Sodium': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REMOVE columns Vegetarian, Others\n",
    "df = df.remove_columns(['Vegetarian'])\n",
    "\n",
    "df['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cooking_method': Value(dtype='string', id=None),\n",
       " 'ingredients': Value(dtype='string', id=None),\n",
       " 'recipe_name': Value(dtype='string', id=None),\n",
       " 'tags': Value(dtype='string', id=None),\n",
       " 'Dairy Free': Value(dtype='int64', id=None),\n",
       " 'Gluten Free': Value(dtype='int64', id=None),\n",
       " 'Low Carb': Value(dtype='int64', id=None),\n",
       " 'Low Fat': Value(dtype='int64', id=None),\n",
       " 'Low Sodium': Value(dtype='int64', id=None),\n",
       " 'Veg': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RENAME columns Vegetarian&Dessert to Veg, Others&Dessert to NonVeg\n",
    "\n",
    "# Define a function to rename columns\n",
    "def rename_columns(example):\n",
    "    # Rename 'Vegetarian&Dessert' to 'Veg'\n",
    "    if 'Vegetarian&Desserts' in example:\n",
    "        example['Veg'] = example.pop('Vegetarian&Desserts')\n",
    "    # Rename 'Others&Dessert' to 'NonVeg'\n",
    "    if 'Others&D' in example:\n",
    "        example['NonVeg'] = example.pop('Others&D')\n",
    "    return example\n",
    "\n",
    "# Apply the rename_columns function to each example in the dataset\n",
    "for split in df.keys():\n",
    "    df[split] = df[split].map(rename_columns)\n",
    "\n",
    "df['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cooking_method': Value(dtype='string', id=None),\n",
       " 'ingredients': Value(dtype='string', id=None),\n",
       " 'recipe_name': Value(dtype='string', id=None),\n",
       " 'tags': Value(dtype='string', id=None),\n",
       " 'Dairy Free': Value(dtype='bool', id=None),\n",
       " 'Gluten Free': Value(dtype='bool', id=None),\n",
       " 'Low Carb': Value(dtype='bool', id=None),\n",
       " 'Low Fat': Value(dtype='bool', id=None),\n",
       " 'Low Sodium': Value(dtype='bool', id=None),\n",
       " 'Veg': Value(dtype='bool', id=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAST variables to boolean\n",
    "df['train'] = df['train'].cast(Features({\n",
    "    'cooking_method' : Value('string'),\n",
    "    'ingredients' : Value('string'),\n",
    "    'recipe_name' : Value('string'),\n",
    "    'tags' : Value('string'),\n",
    "    'Dairy Free': Value('bool'),\n",
    "    'Gluten Free': Value('bool'),\n",
    "    'Low Carb': Value('bool'),\n",
    "    'Low Fat': Value('bool'),\n",
    "    'Low Sodium': Value('bool'),\n",
    "    'Veg': Value('bool')\n",
    "}))\n",
    "\n",
    "df['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.50841116864455"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of Veg recipes\n",
    "\n",
    "sum(df['train']['Veg'])/len(df['train'])*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: stratify ?!?!?!?!?!??!?!?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"count = 0\\nfor i in tqdm(range(len(df['train']))):\\n    if len(df['train']['cooking_method'][i].split()) > 512:\\n        count += 1\\n\\nprint(count)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many recipes have 'cooking_method' of more than 512 tokens\n",
    "\n",
    "\"\"\"count = 0\n",
    "for i in tqdm(range(len(df['train']))):\n",
    "    if len(df['train']['cooking_method'][i].split()) > 512:\n",
    "        count += 1\n",
    "\n",
    "print(count)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop these instances\n",
    "df['train'] = df['train'].filter(lambda x: len(x['cooking_method'].split()) <= 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(df['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.1867716535433"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['train']['Veg'])/len(df['train'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': (23813, 10), 'train': (44449, 10), 'validation': (11113, 10)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df['train'].train_test_split(test_size=0.3, seed = seed)\n",
    "train_validation = df['train'].train_test_split(test_size=0.2, seed = seed)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset['test'] = df['test']\n",
    "dataset['train'] = train_validation['train']\n",
    "dataset['validation'] = train_validation['test']\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Notice that from now on it is immediate to switch to the multi-labels case !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cooking_method', 'ingredients', 'recipe_name', 'tags', 'Dairy Free', 'Gluten Free', 'Low Carb', 'Low Fat', 'Low Sodium', 'Veg'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Veg']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in dataset['train'].features.keys() if label not in ['cooking_method','ingredients','recipe_name','tags','Dairy Free','Gluten Free','Low Carb','Low Fat','Low Sodium','NonVeg']]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'Veg'}, {'Veg': 0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "\n",
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"cooking_method\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512)\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7c41b821694bd083f1a60ba423e5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23813 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c94e0052d814bc88167618d733ae9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a566b0a5076940ed97a4b495afbf8e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = encoded_dataset['train'][0]['input_ids']\n",
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] ['bring a pot of generously salted water to boil and cook the fusilli per package instructions. drain and set aside. ','whisk together the oil, vinegar, oregano, honey, 2 tablespoons parmesan and salt and pepper in a large bowl. add the warm pasta, then toss to coat and sprinkle with the remaining 2 tablespoons parmesan. add the artichokes, red peppers, olives, mozzarella and salami and toss well to combine. sprinkle with fresh basil.'] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!! useful for multi-labels case: see which labels it has\n",
    "[id2label[idx] for idx, label in enumerate(encoded_dataset['train'][0]['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4ecc9f1e8b4de89ad84ac1da40f99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# NOTE we need to change problem_type to multi_label_classification.....\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", \n",
    "                                                           problem_type=\"binary_classification\",\n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"google-bert/bert-base-cased\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=None)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = None)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./models/bert-finetuned-group15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"meat meat meat meat\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "outputs = trainer.model(**encoding)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3627, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "predictions = np.zeros(probs.shape)\n",
    "\"\"\"togliere commenti per stampare le labels corrispondenti\"\"\"\n",
    "# predictions[np.where(probs >= 0.7)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "#predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
