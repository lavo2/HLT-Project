{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9E5EggSQXnjf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# To use Google Colab:\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from utils import *\n",
        "\n",
        "\"\"\"\n",
        "# To use Google Colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WEuMjrYxnTd"
      },
      "source": [
        "## Load cleaned dataset\n",
        "We use the dataset obtained in the notebook `Data_Understanding.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MdT4MybNXnjh"
      },
      "outputs": [],
      "source": [
        "# Load the data locally\n",
        "df = pd.read_csv('dataset/dataset.csv')\n",
        "\n",
        "# Load the data from GDrive\n",
        "# df = pd.read_csv('/content/drive/MyDrive/datasets/dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGSgkoNIamwS"
      },
      "source": [
        "# Named Entity Recognition to Extract the Ingredients\n",
        "In the following we'll use some NER models to extract all the ingredients from the recipes in order to train a network with them afterwards. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FoodBaseBERT\n",
        "We start considering a fine-tuned version of the `bert-base-cased` architecture, which can be found at the following [link](https://huggingface.co/Dizex/FoodBaseBERT-NER).\n",
        "\n",
        "Let's compare different pipelines on the same recipe: the first of the DataFrame. For the First and Second pipelines we refer to this [documentation](https://huggingface.co/transformers/v4.10.1/_modules/transformers/pipelines/token_classification.html), while for the Third we implemented by hand the construction of the tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Dizex/FoodBaseBERT\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"Dizex/FoodBaseBERT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we check if we can use the hugging face superpowers. In particular we want to use the `aggregation_strategy` for the split tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"['Set the racks in the middle and upper thirds of the oven and preheat the oven to 425 F', 'In a large skillet over medium heat, heat the olive oil until shimmering. Add the onion, garlic and red pepper flakes and cook until golden, stirring occasionally, about 5 minutes.', 'Add the fennel and cook until the vegetables are soft and translucent, an additional 3 to 5 minutes.', 'Reduce the heat to medium and add the tomatoes with their juices. Using the back of a wooden spoon, smash the tomatoes and cook for 5 minutes.', 'Add the basil, wine, olives, 1 teaspoon salt, and 1/8 teaspoon black pepper.', 'Reduce to low and simmer for 15 minutes, or until the sauce is slightly thickened, while you prepare the fish.', 'Pat the fillets dry, lightly spray them with cooking spray, and season with salt and pepper.', 'In a heavy ovenproof skillet over high heat, heat the olive oil until shimmering. Add the fillets, rounded-side down, and cook for 2 minutes.', 'Carefully flip the fillets with a metal spatula and place the skillet in the oven. Bake until the fish is no longer translucent, 8 to 10 minutes.', 'Switch the oven to broil and place the skillet on the upper rack. Broil until the tops of the fillets are golden brown, 2 to 4 minutes.', 'Arrange the fillets on individual plates, spoon on the sauce, and serve.']\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the first recipe\n",
        "recipe = df['cooking_method'][0]\n",
        "recipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. First Pipeline\n",
        "We can notice that the performances aren't good; for example `on` `##ion`, `f` `##enne` `##l` are split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'FOOD',\n",
              "  'score': 0.99878013,\n",
              "  'word': 'olive oil',\n",
              "  'start': 138,\n",
              "  'end': 147},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9983912,\n",
              "  'word': 'on',\n",
              "  'start': 174,\n",
              "  'end': 176},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9979122,\n",
              "  'word': '##ion',\n",
              "  'start': 176,\n",
              "  'end': 179},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9981351,\n",
              "  'word': 'garlic',\n",
              "  'start': 181,\n",
              "  'end': 187},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99817646,\n",
              "  'word': 'red pepper flakes',\n",
              "  'start': 192,\n",
              "  'end': 209},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99844223,\n",
              "  'word': 'f',\n",
              "  'start': 284,\n",
              "  'end': 285},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9983156,\n",
              "  'word': '##enne',\n",
              "  'start': 285,\n",
              "  'end': 289},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9981218,\n",
              "  'word': '##l',\n",
              "  'start': 289,\n",
              "  'end': 290},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9989028,\n",
              "  'word': 'vegetables',\n",
              "  'start': 310,\n",
              "  'end': 320},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9990877,\n",
              "  'word': 'tomato',\n",
              "  'start': 418,\n",
              "  'end': 424},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9992041,\n",
              "  'word': '##es',\n",
              "  'start': 424,\n",
              "  'end': 426},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9978265,\n",
              "  'word': 'juice',\n",
              "  'start': 438,\n",
              "  'end': 443},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99859935,\n",
              "  'word': '##s',\n",
              "  'start': 443,\n",
              "  'end': 444},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9987167,\n",
              "  'word': 'tomato',\n",
              "  'start': 490,\n",
              "  'end': 496},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9990983,\n",
              "  'word': '##es',\n",
              "  'start': 496,\n",
              "  'end': 498},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9987276,\n",
              "  'word': 'b',\n",
              "  'start': 534,\n",
              "  'end': 535},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9973712,\n",
              "  'word': '##asi',\n",
              "  'start': 535,\n",
              "  'end': 538},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9984188,\n",
              "  'word': '##l',\n",
              "  'start': 538,\n",
              "  'end': 539},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9984682,\n",
              "  'word': 'wine',\n",
              "  'start': 541,\n",
              "  'end': 545},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99872345,\n",
              "  'word': 'olive',\n",
              "  'start': 547,\n",
              "  'end': 552},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9983392,\n",
              "  'word': '##s',\n",
              "  'start': 552,\n",
              "  'end': 553},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99890685,\n",
              "  'word': 'salt',\n",
              "  'start': 566,\n",
              "  'end': 570},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.998397,\n",
              "  'word': 'black pepper',\n",
              "  'start': 589,\n",
              "  'end': 601},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99872714,\n",
              "  'word': 'sauce',\n",
              "  'start': 660,\n",
              "  'end': 665},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99911255,\n",
              "  'word': 'fish',\n",
              "  'start': 711,\n",
              "  'end': 715},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9975388,\n",
              "  'word': 'fill',\n",
              "  'start': 728,\n",
              "  'end': 732},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9977088,\n",
              "  'word': '##ets',\n",
              "  'start': 732,\n",
              "  'end': 735},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99713683,\n",
              "  'word': 'cooking spray',\n",
              "  'start': 765,\n",
              "  'end': 778},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9985165,\n",
              "  'word': 'salt',\n",
              "  'start': 796,\n",
              "  'end': 800},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9978824,\n",
              "  'word': 'pepper',\n",
              "  'start': 805,\n",
              "  'end': 811},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9985263,\n",
              "  'word': 'olive oil',\n",
              "  'start': 870,\n",
              "  'end': 879},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99796486,\n",
              "  'word': 'fill',\n",
              "  'start': 906,\n",
              "  'end': 910},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9975062,\n",
              "  'word': '##ets',\n",
              "  'start': 910,\n",
              "  'end': 913},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99319696,\n",
              "  'word': 'fill',\n",
              "  'start': 980,\n",
              "  'end': 984},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9893545,\n",
              "  'word': '##ets',\n",
              "  'start': 984,\n",
              "  'end': 987},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99900985,\n",
              "  'word': 'fish',\n",
              "  'start': 1059,\n",
              "  'end': 1063},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99698883,\n",
              "  'word': 'fill',\n",
              "  'start': 1204,\n",
              "  'end': 1208},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9976667,\n",
              "  'word': '##ets',\n",
              "  'start': 1208,\n",
              "  'end': 1211},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99807644,\n",
              "  'word': 'fill',\n",
              "  'start': 1261,\n",
              "  'end': 1265},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99862325,\n",
              "  'word': '##ets',\n",
              "  'start': 1265,\n",
              "  'end': 1268},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9987708,\n",
              "  'word': 'sauce',\n",
              "  'start': 1304,\n",
              "  'end': 1309}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
        "ner_result = pipe(recipe)\n",
        "\n",
        "ner_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Second Pipeline\n",
        "These parameters perform much better! For example `onion` and `fennel` are now kept intact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'FOOD',\n",
              "  'score': 0.99878013,\n",
              "  'word': 'olive oil',\n",
              "  'start': 138,\n",
              "  'end': 147},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9983912,\n",
              "  'word': 'onion',\n",
              "  'start': 174,\n",
              "  'end': 179},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9981351,\n",
              "  'word': 'garlic',\n",
              "  'start': 181,\n",
              "  'end': 187},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9982384,\n",
              "  'word': 'red pepper flakes',\n",
              "  'start': 192,\n",
              "  'end': 209},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99844223,\n",
              "  'word': 'fennel',\n",
              "  'start': 284,\n",
              "  'end': 290},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9989028,\n",
              "  'word': 'vegetables',\n",
              "  'start': 310,\n",
              "  'end': 320},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9992041,\n",
              "  'word': 'tomatoes',\n",
              "  'start': 418,\n",
              "  'end': 426},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99859935,\n",
              "  'word': 'juices',\n",
              "  'start': 438,\n",
              "  'end': 444},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9990983,\n",
              "  'word': 'tomatoes',\n",
              "  'start': 490,\n",
              "  'end': 498},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9987276,\n",
              "  'word': 'basil',\n",
              "  'start': 534,\n",
              "  'end': 539},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9984682,\n",
              "  'word': 'wine',\n",
              "  'start': 541,\n",
              "  'end': 545},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99872345,\n",
              "  'word': 'olives',\n",
              "  'start': 547,\n",
              "  'end': 553},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99890685,\n",
              "  'word': 'salt',\n",
              "  'start': 566,\n",
              "  'end': 570},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.998397,\n",
              "  'word': 'black pepper',\n",
              "  'start': 589,\n",
              "  'end': 601},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99872714,\n",
              "  'word': 'sauce',\n",
              "  'start': 660,\n",
              "  'end': 665},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99911255,\n",
              "  'word': 'fish',\n",
              "  'start': 711,\n",
              "  'end': 715},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9977088,\n",
              "  'word': 'fillets',\n",
              "  'start': 728,\n",
              "  'end': 735},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99713683,\n",
              "  'word': 'cooking spray',\n",
              "  'start': 765,\n",
              "  'end': 778},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9985165,\n",
              "  'word': 'salt',\n",
              "  'start': 796,\n",
              "  'end': 800},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9978824,\n",
              "  'word': 'pepper',\n",
              "  'start': 805,\n",
              "  'end': 811},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9985263,\n",
              "  'word': 'olive oil',\n",
              "  'start': 870,\n",
              "  'end': 879},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99796486,\n",
              "  'word': 'fillets',\n",
              "  'start': 906,\n",
              "  'end': 913},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99319696,\n",
              "  'word': 'fillets',\n",
              "  'start': 980,\n",
              "  'end': 987},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99900985,\n",
              "  'word': 'fish',\n",
              "  'start': 1059,\n",
              "  'end': 1063},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9976667,\n",
              "  'word': 'fillets',\n",
              "  'start': 1204,\n",
              "  'end': 1211},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.99862325,\n",
              "  'word': 'fillets',\n",
              "  'start': 1261,\n",
              "  'end': 1268},\n",
              " {'entity_group': 'FOOD',\n",
              "  'score': 0.9987708,\n",
              "  'word': 'sauce',\n",
              "  'start': 1304,\n",
              "  'end': 1309}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"MAX\")\n",
        "ner_result = pipe(recipe)\n",
        "\n",
        "ner_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Third Pipeline\n",
        "Now let's define by hand what we would like to happen: \n",
        "- if there are two adjacent B-words, and the second one starts with '#', join them\n",
        "- if an I-word starts with '#', join it to the precedent ingredient\n",
        "\n",
        "We can notice that our pipeline works as well as the one above, the difference is that the HugginFace pipeline returns a dictionary while our pipeline returns a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rlWpsamvhuFX"
      },
      "outputs": [],
      "source": [
        "def get_ingredients(recipe: str, ner_result: list):\n",
        "    ingredients = []\n",
        "    last_added = 0\n",
        "    b_word = 'B-FOOD'\n",
        "    i_word = 'I-FOOD'\n",
        "\n",
        "    for i in range(len(ner_result)):\n",
        "\n",
        "        if ner_result[i]['entity'] == b_word:\n",
        "            # check if previous word was a segmentation of the same one\n",
        "            if ner_result[i]['word'].startswith('#') and ner_result[i-1]['entity'] == b_word:\n",
        "                # if (for any reason (it happens)) the first word is a segment, we ignore it\n",
        "                if last_added == 0:\n",
        "                    continue\n",
        "                ingredients[last_added-1] += recipe[ner_result[i]['start'] : ner_result[i]['end']]\n",
        "            else:\n",
        "                # get the ingredient from the recipe given its position\n",
        "                ingredients.append(recipe[ner_result[i]['start'] : ner_result[i]['end']])\n",
        "                last_added += 1\n",
        "\n",
        "        elif ner_result[i]['entity'] == i_word:\n",
        "            # check if segmentation is occurring\n",
        "            if ner_result[i]['word'].startswith('#'):\n",
        "                # if (for any reason (it happens)) the first word is a segment, we ignore it\n",
        "                if last_added == 0:\n",
        "                    continue\n",
        "                ingredients[last_added-1] += recipe[ner_result[i]['start'] : ner_result[i]['end']]\n",
        "            elif last_added == 0:\n",
        "                ingredients.append(recipe[ner_result[i]['start'] : ner_result[i]['end']])\n",
        "                last_added += 1\n",
        "            else:\n",
        "                ingredients[last_added-1] = ingredients[last_added-1] + ' ' + recipe[ner_result[i]['start'] : ner_result[i]['end']]\n",
        "\n",
        "    return ingredients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['olive oil',\n",
              " 'onion',\n",
              " 'garlic',\n",
              " 'red pepper flakes',\n",
              " 'fennel',\n",
              " 'vegetables',\n",
              " 'tomatoes',\n",
              " 'juices',\n",
              " 'tomatoes',\n",
              " 'basil',\n",
              " 'wine',\n",
              " 'olives',\n",
              " 'salt',\n",
              " 'black pepper',\n",
              " 'sauce',\n",
              " 'fish',\n",
              " 'fillets',\n",
              " 'cooking spray',\n",
              " 'salt',\n",
              " 'pepper',\n",
              " 'olive oil',\n",
              " 'fillets',\n",
              " 'fillets',\n",
              " 'fish',\n",
              " 'fillets',\n",
              " 'fillets',\n",
              " 'sauce']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "ner_result = pipe(recipe)\n",
        "\n",
        "ingredients = get_ingredients(recipe, ner_result)\n",
        "ingredients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: indagare se ci sono differenze sostanziali a livello di tempistiche tra la second e la third pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creation of the Vocabulary with FoodBaseBERT\n",
        "Let's use the Third pipeline to to obtain the dictionary of ingredients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9fcb48f58ef84beaa5986254a5382e60",
            "9030c8d9f9df477485087c7f303d3440",
            "680922e095054ba0955df5843d60ea5e",
            "a0d63cde0dd34868878d611d5e43691a",
            "8ea3328b099e40b495a2eabbaf0fcb63",
            "2894def650754b60888bbc7f0310caa9",
            "0b4f52d882c547c2b0e03d9b270fd923",
            "eb3ec11282b04f70b9cc33aa191fb9b1",
            "b62bac09b23245a5b00a180a2d1e026f",
            "274317b98ba64230a96eb86a8537079f",
            "c8b1d9f726954c45a79ad54bf9be3637"
          ]
        },
        "id": "oluqXpw0qerQ",
        "outputId": "718f3038-b049-412b-9532-37d3ff3a8636"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\chucki\\Desktop\\projects\\HLT-Project\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model moved to GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n"
          ]
        }
      ],
      "source": [
        "# we create both the vocabulary and the list of ingredients for each recipe\n",
        "ingredients_v = set()\n",
        "ingredients_list = []\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to('cuda')\n",
        "    print(\"Model moved to GPU.\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Model will run on CPU.\")\n",
        "\n",
        "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "for i, recipe in tqdm(enumerate(df.ingredients), total=len(df.ingredients)):\n",
        "    \n",
        "    ner_result = pipe(recipe)\n",
        "    ingredients = get_ingredients(recipe, ner_result)\n",
        "\n",
        "    ingredients_list.append([])\n",
        "    for ingredient in ingredients:\n",
        "        # we add the ingredient to the vocabulary\n",
        "        ingredients_v.add(ingredient)\n",
        "        # we append the ingredient to the list of ingredients for the current recipe\n",
        "        ingredients_list[i].append(ingredient)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Loading\n",
        "\n",
        "We read the csv file obtained from `Data_Understanding.ipynb` which is perfectly balanced between `Vegetarian` and `Meat&Fish` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = './dataset/dataset_balanced_10k.csv'\n",
        "\n",
        "df = pd.read_csv(PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PoS tagging and lemmatization with spaCy\n",
        "\n",
        "to use spaCy we need to install the model with the following command:\n",
        "\n",
        "python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser and NER\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# apply part-of-speech tagging to the ingredient\n",
        "def pos_tagging(ingredient):\n",
        "    doc = nlp(ingredient)\n",
        "    return [(token.text, token.pos_) for token in doc]\n",
        "\n",
        "# return the string without adjectives, verbs and proper nouns\n",
        "def get_nouns_verbs(ingredient):\n",
        "    tagged = pos_tagging(ingredient)\n",
        "    return ' '.join([word for word, pos in tagged if pos not in  ['ADJ', 'VERB', 'PROPN']])\n",
        "\n",
        "# lemmatize the ingredient\n",
        "def lemmatize(ingredient):\n",
        "    doc = nlp(ingredient)\n",
        "    return ' '.join([token.lemma_ for token in doc])\n",
        "\n",
        "\n",
        "def clean_text(s):\n",
        "    s = s.lower()\n",
        "    s1 = re.sub(r'[^a-z\\s]', '', s)\n",
        "    # remove multiple spaces and starting and ending spaces\n",
        "    s2 = re.sub(r'\\s+', ' ', s1).strip()\n",
        "    return s2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now we test these functions on the ingredient ` 5 calamari rings `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingredient: \t\t\t 5 calamari rings\n",
            "Cleaned ingredient: \t\tcalamari rings\n",
            "PoS tagging: \t\t\t[('calamari', 'PROPN'), ('rings', 'NOUN')]\n",
            "Without ADJ, PROPN, VERB: \trings\n",
            "Lemmatized: \t\t\tring\n"
          ]
        }
      ],
      "source": [
        "ingredient = ' 5 calamari rings'\n",
        "\n",
        "clean_ingredient = clean_text(ingredient)\n",
        "print(f'Ingredient: \\t\\t\\t{ingredient}')\n",
        "print(f'Cleaned ingredient: \\t\\t{clean_ingredient}')\n",
        "print(f'PoS tagging: \\t\\t\\t{pos_tagging(clean_ingredient)}')\n",
        "print(f'Without ADJ, PROPN, VERB: \\t{get_nouns_verbs(clean_ingredient)}')\n",
        "print(f'Lemmatized: \\t\\t\\t{lemmatize(get_nouns_verbs(clean_ingredient))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we apply these function to both the vocabulary and the list of ingredients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create the vocabulary\n",
        "vocabulary = set()\n",
        "for ingredient in ingredients_v:\n",
        "    clean_ingredient = clean_text(ingredient)\n",
        "    vocabulary.add(lemmatize(get_nouns_verbs(clean_ingredient)))\n",
        "\n",
        "# create the list of ingredients for each recipe\n",
        "ingredients_list_clean = []\n",
        "for recipe in ingredients_list:\n",
        "    ingredients_list_clean.append([])\n",
        "    for ingredient in recipe:\n",
        "        clean_ingredient = clean_text(ingredient)\n",
        "        ingredients_list_clean[-1].append(lemmatize(get_nouns_verbs(clean_ingredient)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the vocabulary and ingredients list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixaVKDGy0qwN"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# save the vocabulary\n",
        "PATH = '/content/drive/MyDrive/datasets/vocabulary_10k.csv'\n",
        "\n",
        "with open(PATH, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for ingredient in vocabulary:\n",
        "        writer.writerow([ingredient])\n",
        "\n",
        "print(f\"Set saved to '{PATH}'.\")\n",
        "\n",
        "\n",
        "#save the ingredients list\n",
        "ingredients_df = pd.DataFrame(ingredients_list_clean)\n",
        "\n",
        "ingredients_df.to_csv('./dataset/ingredient_list_10k.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## DistilBert\n",
        "\n",
        "\n",
        "Now we consider a fine-tuned version of the distilbert-base-cased architecture, which can be found at the following [link](https://github.com/chambliss/foodbert).\n",
        "\n",
        "We chose to work with the feature `ingredients` because the examples provided in the GitHub repository for the fine-tuned model were more similar to this feature than the `cooking_method` column.\n",
        "\n",
        "NOTE: The model requires a conda environment to be executed. To get the required setup, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Miniconda\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local\n",
        "\n",
        "# Update PATH\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
        "\n",
        "# Clone your repo\n",
        "!git clone https://github.com/chambliss/foodbert.git\n",
        "\n",
        "# Change directory to the repo\n",
        "%cd foodbert\n",
        "\n",
        "# Create the conda environment\n",
        "!conda env create -f environment.yml\n",
        "\n",
        "# Activate the conda environment\n",
        "\n",
        "%%bash\n",
        "source /usr/local/etc/profile.d/conda.sh && conda activate hf-nlp\n",
        "pip install -e .\n",
        "# Now you can run other commands that require the conda environment to be active"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from food_extractor.food_model import FoodModel\n",
        "model = FoodModel(\"chambliss/distilbert-for-food-extraction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('./dataset/dataset_balanced_10k.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cooking_method</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>tags</th>\n",
              "      <th>Vegetarian</th>\n",
              "      <th>Dairy Free</th>\n",
              "      <th>Gluten Free</th>\n",
              "      <th>Low Carb</th>\n",
              "      <th>Low Fat</th>\n",
              "      <th>Low Sodium</th>\n",
              "      <th>Dessert</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Dairy</th>\n",
              "      <th>Vegetarian&amp;Dessert</th>\n",
              "      <th>Meat&amp;Fish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['To bone turkey, place on a work surface, bre...</td>\n",
              "      <td>['1 (12 to 14 pound) turkey', '3 tablespoons e...</td>\n",
              "      <td>Poultry,Turkey Recipes,Main Dish</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Combine all the ingredients in a blender and...</td>\n",
              "      <td>['2 1/4 cups freshly squeezed orange juice', '...</td>\n",
              "      <td>Liquor Recipes,Tequila Recipes,Fruit,Pureeing ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Pulse the black peppercorns in a spice grind...</td>\n",
              "      <td>['1 tablespoon black peppercorns', '3/4 cup ci...</td>\n",
              "      <td>Sauce Recipes,Barbecue Restaurants,Gluten Free...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Pour water, lemon juice, and simple syrup in...</td>\n",
              "      <td>['8 cups cold water', '2 cups freshly squeezed...</td>\n",
              "      <td>Make Ahead,American,Lemonade Recipes,Tea Recip...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Toss all ingredients together and season wit...</td>\n",
              "      <td>['2 roasted red and yellow bell peppers, peele...</td>\n",
              "      <td>Easy Main Dish,Easy,Main Dish,American,Southwe...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      cooking_method  \\\n",
              "0  ['To bone turkey, place on a work surface, bre...   \n",
              "1  ['Combine all the ingredients in a blender and...   \n",
              "2  ['Pulse the black peppercorns in a spice grind...   \n",
              "3  ['Pour water, lemon juice, and simple syrup in...   \n",
              "4  ['Toss all ingredients together and season wit...   \n",
              "\n",
              "                                         ingredients  \\\n",
              "0  ['1 (12 to 14 pound) turkey', '3 tablespoons e...   \n",
              "1  ['2 1/4 cups freshly squeezed orange juice', '...   \n",
              "2  ['1 tablespoon black peppercorns', '3/4 cup ci...   \n",
              "3  ['8 cups cold water', '2 cups freshly squeezed...   \n",
              "4  ['2 roasted red and yellow bell peppers, peele...   \n",
              "\n",
              "                                                tags  Vegetarian  Dairy Free  \\\n",
              "0                   Poultry,Turkey Recipes,Main Dish           0           0   \n",
              "1  Liquor Recipes,Tequila Recipes,Fruit,Pureeing ...           1           0   \n",
              "2  Sauce Recipes,Barbecue Restaurants,Gluten Free...           1           0   \n",
              "3  Make Ahead,American,Lemonade Recipes,Tea Recip...           1           0   \n",
              "4  Easy Main Dish,Easy,Main Dish,American,Southwe...           1           0   \n",
              "\n",
              "   Gluten Free  Low Carb  Low Fat  Low Sodium  Dessert  Meat  Fish  Dairy  \\\n",
              "0            0         0        0           0        0     1     0      0   \n",
              "1            1         0        1           0        0     0     0      0   \n",
              "2            1         0        1           0        0     0     0      0   \n",
              "3            1         0        1           1        0     0     0      1   \n",
              "4            1         0        0           0        0     0     0      0   \n",
              "\n",
              "   Vegetarian&Dessert  Meat&Fish  \n",
              "0                   0          1  \n",
              "1                   1          0  \n",
              "2                   1          0  \n",
              "3                   1          0  \n",
              "4                   1          0  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we associate each recipe with its ingredients\n",
        "ingredients_list = df.ingredients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we save the labels for label\n",
        "labels = df[df.columns[3:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for each recipe we extract the ingredients and save them in a list\n",
        "ner_list = []\n",
        "for i, recipe in tqdm(enumerate(ingredients_list), total=len(ingredients_list)):\n",
        "    try:\n",
        "        ner_list.append([ingredient['text'] for ingredient in model.extract_foods(recipe)[0]['Ingredient']])\n",
        "    except Exception as e:\n",
        "        print(i)\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now we create the vocabulary by extracting the ingredients from the list of ingredients\n",
        "ner_ingredients = set()\n",
        "for el in ner_list:\n",
        "    for ingredient in el:\n",
        "        ner_ingredients.add(ingredient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### save the vocabulary and list of ingredients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('/content/drive/MyDrive/ner_ingredients_balanced.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for item in list(ner_ingredients):\n",
        "        writer.writerow([item])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#removed_positions = [121, 364, 527, 613, 1054, 2064, 3102, 3367, 5815, 6018, 6174, 6180, 6507, 7921, 8194, 9783]\n",
        "#len(labels)\n",
        "\n",
        "#labels = labels.drop(removed_positions)\n",
        "#df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#labels.to_csv('./dataset/ner_labels_balanced.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the vocabulary\n",
        "import csv\n",
        "\n",
        "with open('/content/drive/MyDrive/ner_recipes_balanced.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for item in list(ner_list):\n",
        "        writer.writerow([item])\n",
        "\n",
        "\n",
        "#save the ingredients list\n",
        "ingredients_df = pd.DataFrame(ingredients_list_clean)\n",
        "\n",
        "ingredients_df.to_csv('./dataset/ingredient_list_10k.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b4f52d882c547c2b0e03d9b270fd923": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "274317b98ba64230a96eb86a8537079f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2894def650754b60888bbc7f0310caa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680922e095054ba0955df5843d60ea5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb3ec11282b04f70b9cc33aa191fb9b1",
            "max": 82011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b62bac09b23245a5b00a180a2d1e026f",
            "value": 1870
          }
        },
        "8ea3328b099e40b495a2eabbaf0fcb63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9030c8d9f9df477485087c7f303d3440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2894def650754b60888bbc7f0310caa9",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4f52d882c547c2b0e03d9b270fd923",
            "value": "  2%"
          }
        },
        "9fcb48f58ef84beaa5986254a5382e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9030c8d9f9df477485087c7f303d3440",
              "IPY_MODEL_680922e095054ba0955df5843d60ea5e",
              "IPY_MODEL_a0d63cde0dd34868878d611d5e43691a"
            ],
            "layout": "IPY_MODEL_8ea3328b099e40b495a2eabbaf0fcb63"
          }
        },
        "a0d63cde0dd34868878d611d5e43691a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274317b98ba64230a96eb86a8537079f",
            "placeholder": "​",
            "style": "IPY_MODEL_c8b1d9f726954c45a79ad54bf9be3637",
            "value": " 1869/82011 [14:58&lt;16:44:23,  1.33it/s]"
          }
        },
        "b62bac09b23245a5b00a180a2d1e026f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8b1d9f726954c45a79ad54bf9be3637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb3ec11282b04f70b9cc33aa191fb9b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
