{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings on recipes with BERT, Neural Network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, TFBertModel\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading\n",
    "We upload the old dataset (the one used for the slide presentations): `recipes_df_r.csv` is made of 5.000 recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/recipes_df_r.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cooking_method', 'ingredients', 'recipe_name', 'tags',\n",
       "       'Vegetarian&Desserts', 'Others&D', 'Vegetarian', 'Others', 'Dairy Free',\n",
       "       'Gluten Free', 'Low Carb', 'Low Fat', 'Low Sodium'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vegetarian&Desserts\n",
       "0    6670\n",
       "1    3330\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Vegetarian&Desserts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns we need\n",
    "columns = ['cooking_method', 'ingredients', 'Vegetarian&Desserts']\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mantaining Veg distribution (33%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We restrict even more the dataset: keep only 666 Veg and 1.334 Non-Veg recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cooking_method</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>Vegetarian&amp;Desserts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>['Heat a nonstick or cast-iron skillet over me...</td>\n",
       "      <td>['2 slices sourdough sandwich bread or crusty ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>['Blend 15 to 20 seconds, use a spatula to rem...</td>\n",
       "      <td>['8 ounces crushed ice', '1 ounce strawberry j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>['Cut off about 1 inch from both ends of all 4...</td>\n",
       "      <td>['4 medium navel oranges (2 to 2 1/4 pounds), ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>['In a large, heavy bottom saucepan over mediu...</td>\n",
       "      <td>['4 tablespoons unsalted butter', '1 medium le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>['Directions', 'Bring a large pot of salted wa...</td>\n",
       "      <td>['Kosher salt', '1/2 pound medium shell pasta'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cooking_method  \\\n",
       "6734  ['Heat a nonstick or cast-iron skillet over me...   \n",
       "6512  ['Blend 15 to 20 seconds, use a spatula to rem...   \n",
       "7273  ['Cut off about 1 inch from both ends of all 4...   \n",
       "98    ['In a large, heavy bottom saucepan over mediu...   \n",
       "5802  ['Directions', 'Bring a large pot of salted wa...   \n",
       "\n",
       "                                            ingredients  Vegetarian&Desserts  \n",
       "6734  ['2 slices sourdough sandwich bread or crusty ...                    1  \n",
       "6512  ['8 ounces crushed ice', '1 ounce strawberry j...                    0  \n",
       "7273  ['4 medium navel oranges (2 to 2 1/4 pounds), ...                    1  \n",
       "98    ['4 tablespoons unsalted butter', '1 medium le...                    0  \n",
       "5802  ['Kosher salt', '1/2 pound medium shell pasta'...                    0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take 2.000 samples keeping same distribution of feature 'Vegetarian&Desserts'\n",
    "df_v = df[df['Vegetarian&Desserts'] == 1].sample(n=666)\n",
    "df_nv = df[df['Vegetarian&Desserts'] == 0].sample(n=1334)\n",
    "\n",
    "df = pd.concat([df_v, df_nv])\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the cooking_method as a list of strings\n",
    "cooking_methods = df['cooking_method'].values.tolist()\n",
    "type(cooking_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cooking_methods\n",
    "y = df['Vegetarian&Desserts'].values\n",
    "\n",
    "# Assuming 'X' contains your input data (cooking methods) and 'y' contains the target labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize input data using BERT tokenizer\n",
    "max_length = 200  \n",
    "X_train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "X_val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "# Obtain BERT embeddings\n",
    "train_outputs = bert_model(X_train_encodings)\n",
    "val_outputs = bert_model(X_val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BERT embeddings\n",
    "train_embeddings = train_outputs.last_hidden_state\n",
    "val_embeddings = val_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1600, 200, 768]), TensorShape([400, 200, 768]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape, val_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600,), (400,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 1), (400, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape y_train and y_val\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define our Neural Network classifier using Keras, we train it and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.7047 - loss: 0.6005\n",
      "Epoch 2/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.8287 - loss: 0.3739\n",
      "Epoch 3/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9198 - loss: 0.2339\n",
      "Epoch 4/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9791 - loss: 0.1296\n",
      "Epoch 5/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9858 - loss: 0.0934\n",
      "Epoch 6/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9942 - loss: 0.0590\n",
      "Epoch 7/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.9966 - loss: 0.0450\n",
      "Epoch 8/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0356\n",
      "Epoch 9/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0210\n",
      "Epoch 10/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.9997 - loss: 0.0179\n"
     ]
    }
   ],
   "source": [
    "# Define feedforward neural network for classification using Keras\n",
    "input_layer = Input(shape=(max_length, 768))  # BERT embedding size is 768\n",
    "flatten_layer = Flatten()(input_layer)  # Flatten the BERT embeddings\n",
    "dense_layer1 = Dense(128, activation='relu')(flatten_layer)\n",
    "dropout_layer = Dropout(0.2)(dense_layer1)\n",
    "dense_layer2 = Dense(64, activation='relu')(dropout_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense_layer2)  # Assuming binary classification\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_embeddings.numpy(), y_train, epochs=10, batch_size=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84       251\n",
      "           1       0.81      0.55      0.66       149\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.79      0.74      0.75       400\n",
      "weighted avg       0.79      0.79      0.77       400\n",
      "\n",
      "[[232  19]\n",
      " [ 67  82]]\n"
     ]
    }
   ],
   "source": [
    "# predict the output and compare with y_val\n",
    "predicted_labels = model.predict(val_embeddings.numpy())\n",
    "predicted_labels = (predicted_labels > 0.5).astype(int)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_val, predicted_labels))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_val, predicted_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Veg distribution (50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cooking_method</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>Vegetarian&amp;Desserts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>['In a cocktail shaker mix all the ingredients...</td>\n",
       "      <td>['2 ounces vanilla vodka', '1-ounce peach schn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>[\"Make a cone holder: Find a small, sturdy, cl...</td>\n",
       "      <td>['4 ounces semisweet chocolate, chopped into s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>['In a high-sided skillet over medium heat, ad...</td>\n",
       "      <td>['1 teaspoon canola oil', '1/2 red onion, slic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>['Place the garlic in cup of boiling water for...</td>\n",
       "      <td>['5 cloves garlic, peeled', '2 tablespoons oli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>['Drain the beans and set aside. In a bowl, wh...</td>\n",
       "      <td>['1 pound dried navy beans, soaked overnight i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cooking_method  \\\n",
       "7498  ['In a cocktail shaker mix all the ingredients...   \n",
       "6122  [\"Make a cone holder: Find a small, sturdy, cl...   \n",
       "3820  ['In a high-sided skillet over medium heat, ad...   \n",
       "6723  ['Place the garlic in cup of boiling water for...   \n",
       "4699  ['Drain the beans and set aside. In a bowl, wh...   \n",
       "\n",
       "                                            ingredients  Vegetarian&Desserts  \n",
       "7498  ['2 ounces vanilla vodka', '1-ounce peach schn...                    0  \n",
       "6122  ['4 ounces semisweet chocolate, chopped into s...                    1  \n",
       "3820  ['1 teaspoon canola oil', '1/2 red onion, slic...                    0  \n",
       "6723  ['5 cloves garlic, peeled', '2 tablespoons oli...                    0  \n",
       "4699  ['1 pound dried navy beans, soaked overnight i...                    0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/recipes_df_r.csv')\n",
    "\n",
    "# keep only the columns we need\n",
    "columns = ['cooking_method', 'ingredients', 'Vegetarian&Desserts']\n",
    "df = df[columns]\n",
    "\n",
    "# take 3.000 samples balancing the feature 'Vegetarian&Desserts'\n",
    "df_v = df[df['Vegetarian&Desserts'] == 1].sample(n=1500)\n",
    "df_nv = df[df['Vegetarian&Desserts'] == 0].sample(n=1500)\n",
    "\n",
    "df = pd.concat([df_v, df_nv])\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cooking_method as a list of strings\n",
    "cooking_methods = df['cooking_method'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cooking_methods\n",
    "y = df['Vegetarian&Desserts'].values\n",
    "\n",
    "# Assuming 'X' contains your input data (cooking methods) and 'y' contains the target labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2400, 200, 768]), TensorShape([600, 200, 768]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize input data using BERT tokenizer\n",
    "max_length = 200  \n",
    "X_train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "X_val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "# Obtain BERT embeddings\n",
    "train_outputs = bert_model(X_train_encodings)\n",
    "val_outputs = bert_model(X_val_encodings)\n",
    "\n",
    "# Extract BERT embeddings\n",
    "train_embeddings = train_outputs.last_hidden_state\n",
    "val_embeddings = val_outputs.last_hidden_state\n",
    "train_embeddings.shape, val_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape y_train and y_val\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define our Neural Network classifier using Keras, we train it and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5146 - loss: 0.6968\n",
      "Epoch 2/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5791 - loss: 0.6759\n",
      "Epoch 3/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6571 - loss: 0.6279\n",
      "Epoch 4/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7152 - loss: 0.5592\n",
      "Epoch 5/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7675 - loss: 0.5025\n",
      "Epoch 6/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8053 - loss: 0.4781\n",
      "Epoch 7/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8154 - loss: 0.4486\n",
      "Epoch 8/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8359 - loss: 0.4120\n",
      "Epoch 9/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8404 - loss: 0.3937\n",
      "Epoch 10/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8795 - loss: 0.3477\n",
      "Epoch 11/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8834 - loss: 0.3212\n",
      "Epoch 12/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8824 - loss: 0.3208\n",
      "Epoch 13/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9217 - loss: 0.2795\n",
      "Epoch 14/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9058 - loss: 0.2786\n",
      "Epoch 15/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9249 - loss: 0.2587\n",
      "Epoch 16/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9311 - loss: 0.2340\n",
      "Epoch 17/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9420 - loss: 0.2123\n",
      "Epoch 18/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9298 - loss: 0.2117\n",
      "Epoch 19/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9446 - loss: 0.1835\n",
      "Epoch 20/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9524 - loss: 0.1759\n",
      "Epoch 21/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9639 - loss: 0.1669\n",
      "Epoch 22/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9618 - loss: 0.1572\n",
      "Epoch 23/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9670 - loss: 0.1391\n",
      "Epoch 24/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9629 - loss: 0.1471\n",
      "Epoch 25/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9683 - loss: 0.1290\n",
      "Epoch 26/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9647 - loss: 0.1244\n",
      "Epoch 27/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9750 - loss: 0.1083\n",
      "Epoch 28/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9771 - loss: 0.1053\n",
      "Epoch 29/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9731 - loss: 0.1102\n",
      "Epoch 30/30\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9703 - loss: 0.1028\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       300\n",
      "           1       0.77      0.75      0.76       300\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.77      0.77      0.77       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[234  66]\n",
      " [ 74 226]]\n"
     ]
    }
   ],
   "source": [
    "# Define feedforward neural network for classification using Keras\n",
    "input_layer = Input(shape=(max_length, 768))  # BERT embedding size is 768\n",
    "flatten_layer = Flatten()(input_layer)  # Flatten the BERT embeddings\n",
    "dense_layer1 = Dense(64, activation='relu')(flatten_layer)\n",
    "dropout_layer = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(32, activation='relu')(dropout_layer)\n",
    "dropout_layer2 = Dropout(0.2)(dense_layer2)\n",
    "dense_layer3 = Dense(16, activation='relu')(dropout_layer2)\n",
    "dense_layer4 = Dense(8, activation='relu')(dense_layer3)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense_layer4)  # Assuming binary classification\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_embeddings.numpy(), y_train, epochs=30, batch_size=32, verbose=True)\n",
    "# predict the output and compare with y_val\n",
    "predicted_labels = model.predict(val_embeddings.numpy())\n",
    "predicted_labels = (predicted_labels > 0.5).astype(int)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_val, predicted_labels))\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_val, predicted_labels)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
