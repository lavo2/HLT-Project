{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./dataset/recipes_82k.csv')\n",
    "df = pd.read_csv('./dataset/ner_ingredients_balanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nota: quando scarichi il dataset aggiungi all'inizio ingredient per creare il titolo altrimenti prende una lista di ingredienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinch salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rill grate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dill gherkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ingredients\n",
       "0    mango juice\n",
       "1     Pinch salt\n",
       "2           rout\n",
       "3     rill grate\n",
       "4  dill gherkins"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 21:51:34 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8a7ae592d54c8291b9589bebc9f9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 21:51:34 INFO: Downloaded file to /Users/lavo/stanza_resources/resources.json\n",
      "2024-04-30 21:51:34 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-04-30 21:51:34 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-04-30 21:51:34 INFO: Using device: cpu\n",
      "2024-04-30 21:51:34 INFO: Loading: tokenize\n",
      "2024-04-30 21:51:35 INFO: Loading: mwt\n",
      "2024-04-30 21:51:35 INFO: Loading: pos\n",
      "2024-04-30 21:51:35 INFO: Loading: lemma\n",
      "2024-04-30 21:51:35 INFO: Done loading processors!\n",
      "100%|██████████| 8543/8543 [02:42<00:00, 52.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import clean_vocabulary\n",
    "\n",
    "df2 = clean_vocabulary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pinch salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rill grate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dill gherkin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ingredients\n",
       "0   mango juice\n",
       "1    pinch salt\n",
       "2          rout\n",
       "3    rill grate\n",
       "4  dill gherkin"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column name to `ingredients`\n",
    "df.rename(columns={'red chicory': 'ingredients'}, inplace=True)\n",
    "df.info()\n",
    "# add a new instance to df\n",
    "df = df._append({'ingredients': 'red chicory'}, ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We strt processingt his dtaaframe: eliminate words of 2 chars, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    # if you encounter a - or ' (or something else) in the text, replace it with a space\n",
    "    #TODO: right?\n",
    "    s1 = re.sub(r'[^a-z\\s]', ' ', s)\n",
    "    s1 = ' '.join([w for w in s1.split() if len(w) > 2])\n",
    "    # remove multiple spaces and starting and ending spaces\n",
    "    s2 = re.sub(r'\\s+', ' ', s1).strip()\n",
    "    return s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the ingredients column\n",
    "df['ingredients'] = df['ingredients'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 1)\n"
     ]
    }
   ],
   "source": [
    "# count empty strings\n",
    "print(df[df['ingredients'] == ''].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 1)\n"
     ]
    }
   ],
   "source": [
    "# duplicates\n",
    "print(df[df.duplicated()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9868, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8580, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate both empty strings and duplicates\n",
    "df = df.drop_duplicates()\n",
    "df = df[df['ingredients'] != '']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 21:26:30 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110edb2149f844f2abb9553908b0ea56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 21:26:30 INFO: Downloaded file to /Users/irene/stanza_resources/resources.json\n",
      "2024-04-29 21:26:30 WARNING: Language en package default expects mwt, which has been added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d44a99824a40629440a55a0754f565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/tokenize/combined.pt:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5023ecdbc64c4a73aaf126113ccfaf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/mwt/combined.pt:   0%|         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d86cdf077724f3299857bc064a7e310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pos/combined_charlm.pt:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115104a67bf243e1ab0d2f974aa477d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/lemma/combined_nocharlm.pt:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef175adb89d411eba99ad96ce329a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/forward_charlm/1billion.pt:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fdf26a69814f46afad4a8ca0f2113c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/backward_charlm/1billion.pt:   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c2d4a3ea4a46fe8521889090a1a351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pretrain/conll17.pt:   0%|     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 21:27:15 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-04-29 21:27:15 INFO: Using device: cpu\n",
      "2024-04-29 21:27:15 INFO: Loading: tokenize\n",
      "2024-04-29 21:27:15 INFO: Loading: mwt\n",
      "2024-04-29 21:27:15 INFO: Loading: pos\n",
      "2024-04-29 21:27:16 INFO: Loading: lemma\n",
      "2024-04-29 21:27:16 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stanza.pipeline.core.Pipeline at 0x31f231ad0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize, pos, lemma')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how these tools work!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Ingredient: bones fish bones\n",
      "Tokens: ['bones', 'fish', 'bones']\n",
      "POS Tags: ['NOUN', 'NOUN', 'NOUN']\n",
      "Lemmas: ['bone', 'fish', 'bone']\n",
      "\n",
      "Original Ingredient: eyed peas\n",
      "Tokens: ['eyed', 'peas']\n",
      "POS Tags: ['ADJ', 'NOUN']\n",
      "Lemmas: ['eye', 'peas']\n",
      "\n",
      "Original Ingredient: sliced pepperoni\n",
      "Tokens: ['sliced', 'pepperoni']\n",
      "POS Tags: ['VERB', 'NOUN']\n",
      "Lemmas: ['slice', 'pepperoni']\n",
      "\n",
      "Original Ingredient: carrot fronds\n",
      "Tokens: ['carrot', 'fronds']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['carrot', 'frond']\n",
      "\n",
      "Original Ingredient: chocolate sprinkles\n",
      "Tokens: ['chocolate', 'sprinkles']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['chocolate', 'sprinkle']\n",
      "\n",
      "Original Ingredient: lash milk\n",
      "Tokens: ['lash', 'milk']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lash', 'milk']\n",
      "\n",
      "Original Ingredient: goose\n",
      "Tokens: ['goose']\n",
      "POS Tags: ['NOUN']\n",
      "Lemmas: ['goose']\n",
      "\n",
      "Original Ingredient: bucatini pasta\n",
      "Tokens: ['bucatini', 'pasta']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['bucatini', 'pasta']\n",
      "\n",
      "Original Ingredient: lowfat yogurt\n",
      "Tokens: ['lowfat', 'yogurt']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lowfat', 'yogurt']\n",
      "\n",
      "Original Ingredient: russet potato\n",
      "Tokens: ['russet', 'potato']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['russet', 'potato']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each ingredient\n",
    "for ingredient in df[7000:7010]['ingredients']:\n",
    "    # Process ingredient through the pipeline\n",
    "    doc = nlp(ingredient)\n",
    "    \n",
    "    # Extract tokenized forms, part-of-speech tags, and lemmatized forms\n",
    "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    pos_tags = [word.upos for sent in doc.sentences for word in sent.words]\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    \n",
    "    # Print the processed information\n",
    "    print(\"Original Ingredient:\", ingredient)\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "    print(\"Lemmas:\", lemmas)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Ingredient: bones fish bones\n",
      "Tokens: ['bone', 'fish', 'bone']\n",
      "POS Tags: ['NOUN', 'NOUN', 'NOUN']\n",
      "Lemmas: ['bone', 'fish', 'bone']\n",
      "\n",
      "Original Ingredient: eyed peas\n",
      "Tokens: ['peas']\n",
      "POS Tags: ['ADJ', 'NOUN']\n",
      "Lemmas: ['eye', 'peas']\n",
      "\n",
      "Original Ingredient: sliced pepperoni\n",
      "Tokens: ['slice', 'pepperoni']\n",
      "POS Tags: ['VERB', 'NOUN']\n",
      "Lemmas: ['slice', 'pepperoni']\n",
      "\n",
      "Original Ingredient: carrot fronds\n",
      "Tokens: ['carrot', 'frond']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['carrot', 'frond']\n",
      "\n",
      "Original Ingredient: chocolate sprinkles\n",
      "Tokens: ['chocolate', 'sprinkle']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['chocolate', 'sprinkle']\n",
      "\n",
      "Original Ingredient: lash milk\n",
      "Tokens: ['lash', 'milk']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lash', 'milk']\n",
      "\n",
      "Original Ingredient: goose\n",
      "Tokens: ['goose']\n",
      "POS Tags: ['NOUN']\n",
      "Lemmas: ['goose']\n",
      "\n",
      "Original Ingredient: bucatini pasta\n",
      "Tokens: ['bucatini', 'pasta']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['bucatini', 'pasta']\n",
      "\n",
      "Original Ingredient: lowfat yogurt\n",
      "Tokens: ['lowfat', 'yogurt']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lowfat', 'yogurt']\n",
      "\n",
      "Original Ingredient: russet potato\n",
      "Tokens: ['russet', 'potato']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['russet', 'potato']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INTERNAL PROCESSING: ELIMINATE ADJ AND PROPN\n",
    "\n",
    "for ingredient in df[7000:7010]['ingredients']:\n",
    "    # Process ingredient through the pipeline\n",
    "    doc = nlp(ingredient)\n",
    "    \n",
    "    # Extract tokenized forms, part-of-speech tags, and lemmatized forms\n",
    "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    pos_tags = [word.upos for sent in doc.sentences for word in sent.words]\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    \n",
    "    ### NOTICE THAT WE ARE USING `lemmas` INSTEAD OF `tokens`, so we will define our clean dictionary with the pure form of the words (their lemmatization!!!) ###\n",
    "    # eliminate the tokens in `tokens` that are ADJ in `pos_tags`\n",
    "    tokens = [lemmas[i] for i in range(len(tokens)) if pos_tags[i] != 'ADJ' and pos_tags[i] != 'PROPN']\n",
    "    \n",
    "    # Print the processed information\n",
    "    print(\"Original Ingredient:\", ingredient)\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "    print(\"Lemmas:\", lemmas)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: valutare se togliere anche VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, now we will have new empty strings!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of new dictionary\n",
    "cleaned_ingredients = []\n",
    "\n",
    "for ingredient in df['ingredients']:\n",
    "    # Process ingredient through the pipeline\n",
    "    doc = nlp(ingredient)\n",
    "    \n",
    "    # Extract tokenized forms, part-of-speech tags, and lemmatized forms\n",
    "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    pos_tags = [word.upos for sent in doc.sentences for word in sent.words]\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    \n",
    "    ### NOTICE THAT WE ARE USING `lemmas` INSTEAD OF `tokens`, so we will define our clean dictionary with the pure form of the words (their lemmatization!!!) ###\n",
    "    # eliminate the tokens in `tokens` that are ADJ in `pos_tags`\n",
    "    tokens = [lemmas[i] for i in range(len(tokens)) if pos_tags[i] != 'ADJ' and pos_tags[i] != 'PROPN']\n",
    "\n",
    "    # reconvert tokens to a string\n",
    "    cleaned_ingredient = ' '.join(tokens)\n",
    "\n",
    "    # append to the list\n",
    "    cleaned_ingredients.append(cleaned_ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pinch salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tooth coriander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vegetable stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ingredients\n",
       "0      mango juice\n",
       "1       pinch salt\n",
       "2  tooth coriander\n",
       "3            stick\n",
       "4  vegetable stock"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch cleaned_ingredients to a DataFrame\n",
    "cleaned_df = pd.DataFrame(cleaned_ingredients, columns=['ingredients'])\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 1)\n"
     ]
    }
   ],
   "source": [
    "# see how many empty strings we have\n",
    "print(cleaned_df[cleaned_df['ingredients'] == ''].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2517, 1)\n"
     ]
    }
   ],
   "source": [
    "# see duplicates\n",
    "print(cleaned_df[cleaned_df.duplicated()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>clam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>plum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>liqueur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>lobster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>plum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>lettuce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>mustard seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ingredients\n",
       "33               \n",
       "42           clam\n",
       "44               \n",
       "60               \n",
       "74               \n",
       "80           rice\n",
       "92               \n",
       "95               \n",
       "105              \n",
       "110              \n",
       "128          plum\n",
       "139        pepper\n",
       "144        potato\n",
       "146         onion\n",
       "151              \n",
       "162              \n",
       "164       liqueur\n",
       "173     chocolate\n",
       "178              \n",
       "187       lobster\n",
       "198        pepper\n",
       "202              \n",
       "225          plum\n",
       "246        pepper\n",
       "257              \n",
       "261              \n",
       "264       lettuce\n",
       "267              \n",
       "304  mustard seed\n",
       "331          rice"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the duplicates \n",
    "cleaned_df[cleaned_df.duplicated()].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6062, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate both empty strings and duplicates\n",
    "cleaned_df = cleaned_df.drop_duplicates()\n",
    "cleaned_df = cleaned_df[cleaned_df['ingredients'] != '']\n",
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ora ingredients !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/ner_recipes_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['butter', 'brown sugar', 'banana', 'bourbon',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['beef broth', 'tomatoes', 'butter', 'skirt st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['lemons', 'apple cider', 'cloves', 'anise', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sesame oil', 'white wine vinegar', 'soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cocoa', 'cupcakes', 'sugar', 'flour', 'bakin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ingredients\n",
       "0  ['butter', 'brown sugar', 'banana', 'bourbon',...\n",
       "1  ['beef broth', 'tomatoes', 'butter', 'skirt st...\n",
       "2  ['lemons', 'apple cider', 'cloves', 'anise', '...\n",
       "3  ['sesame oil', 'white wine vinegar', 'soy sauc...\n",
       "4  ['cocoa', 'cupcakes', 'sugar', 'flour', 'bakin..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prendo lista degli ingredienti al posto della singola stringa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['butter'\",\n",
       " \" 'brown sugar'\",\n",
       " \" 'banana'\",\n",
       " \" 'bourbon'\",\n",
       " \" 'cinnamon'\",\n",
       " \" 'vanilla ice cream']\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients = []\n",
    "for i in range(len(df)):\n",
    "    ing = (df['ingredients'][i].split(','))\n",
    "    ingredients.append(ing)\n",
    "ingredients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['butter'</td>\n",
       "      <td>'brown sugar'</td>\n",
       "      <td>'banana'</td>\n",
       "      <td>'bourbon'</td>\n",
       "      <td>'cinnamon'</td>\n",
       "      <td>'vanilla ice cream']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['beef broth'</td>\n",
       "      <td>'tomatoes'</td>\n",
       "      <td>'butter'</td>\n",
       "      <td>'skirt steak'</td>\n",
       "      <td>'black pepper'</td>\n",
       "      <td>'mashed potatoes'</td>\n",
       "      <td>'butter'</td>\n",
       "      <td>'milk'</td>\n",
       "      <td>'rosemary leaves'</td>\n",
       "      <td>'black pepper']</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['lemons'</td>\n",
       "      <td>'apple cider'</td>\n",
       "      <td>'cloves'</td>\n",
       "      <td>'anise'</td>\n",
       "      <td>'jalapeno'</td>\n",
       "      <td>'ginger'</td>\n",
       "      <td>'bourbon']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sesame oil'</td>\n",
       "      <td>'white wine vinegar'</td>\n",
       "      <td>'soy sauce'</td>\n",
       "      <td>'sugar'</td>\n",
       "      <td>'Kosher salt'</td>\n",
       "      <td>'asparagus'</td>\n",
       "      <td>'sesame seeds']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cocoa'</td>\n",
       "      <td>'cupcakes'</td>\n",
       "      <td>'sugar'</td>\n",
       "      <td>'flour'</td>\n",
       "      <td>'baking soda'</td>\n",
       "      <td>'Pinch fine salt'</td>\n",
       "      <td>'ut beer'</td>\n",
       "      <td>'stick butter'</td>\n",
       "      <td>'vanilla extract'</td>\n",
       "      <td>'eggs'</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                      1             2               3   \\\n",
       "0      ['butter'          'brown sugar'      'banana'       'bourbon'   \n",
       "1  ['beef broth'             'tomatoes'      'butter'   'skirt steak'   \n",
       "2      ['lemons'          'apple cider'      'cloves'         'anise'   \n",
       "3  ['sesame oil'   'white wine vinegar'   'soy sauce'         'sugar'   \n",
       "4       ['cocoa'             'cupcakes'       'sugar'         'flour'   \n",
       "\n",
       "                4                      5                 6                7   \\\n",
       "0       'cinnamon'   'vanilla ice cream']              None             None   \n",
       "1   'black pepper'      'mashed potatoes'          'butter'           'milk'   \n",
       "2       'jalapeno'               'ginger'        'bourbon']             None   \n",
       "3    'Kosher salt'            'asparagus'   'sesame seeds']             None   \n",
       "4    'baking soda'      'Pinch fine salt'         'ut beer'   'stick butter'   \n",
       "\n",
       "                   8                 9   ...    53    54    55    56    57  \\\n",
       "0                None              None  ...  None  None  None  None  None   \n",
       "1   'rosemary leaves'   'black pepper']  ...  None  None  None  None  None   \n",
       "2                None              None  ...  None  None  None  None  None   \n",
       "3                None              None  ...  None  None  None  None  None   \n",
       "4   'vanilla extract'            'eggs'  ...  None  None  None  None  None   \n",
       "\n",
       "     58    59    60    61    62  \n",
       "0  None  None  None  None  None  \n",
       "1  None  None  None  None  None  \n",
       "2  None  None  None  None  None  \n",
       "3  None  None  None  None  None  \n",
       "4  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ingredients)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sono sudicioni ma la regex dovrebbe pulirli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>butter</td>\n",
       "      <td>brown sugar</td>\n",
       "      <td>banana</td>\n",
       "      <td>bourbon</td>\n",
       "      <td>cinnamon</td>\n",
       "      <td>vanilla ice cream</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beef broth</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>butter</td>\n",
       "      <td>skirt steak</td>\n",
       "      <td>black pepper</td>\n",
       "      <td>mashed potatoes</td>\n",
       "      <td>butter</td>\n",
       "      <td>milk</td>\n",
       "      <td>rosemary leaves</td>\n",
       "      <td>black pepper</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lemons</td>\n",
       "      <td>apple cider</td>\n",
       "      <td>cloves</td>\n",
       "      <td>anise</td>\n",
       "      <td>jalapeno</td>\n",
       "      <td>ginger</td>\n",
       "      <td>bourbon</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sesame oil</td>\n",
       "      <td>white wine vinegar</td>\n",
       "      <td>soy sauce</td>\n",
       "      <td>sugar</td>\n",
       "      <td>kosher salt</td>\n",
       "      <td>asparagus</td>\n",
       "      <td>sesame seeds</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cocoa</td>\n",
       "      <td>cupcakes</td>\n",
       "      <td>sugar</td>\n",
       "      <td>flour</td>\n",
       "      <td>baking soda</td>\n",
       "      <td>pinch fine salt</td>\n",
       "      <td>beer</td>\n",
       "      <td>stick butter</td>\n",
       "      <td>vanilla extract</td>\n",
       "      <td>eggs</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                   1          2            3             4   \\\n",
       "0      butter         brown sugar     banana      bourbon      cinnamon   \n",
       "1  beef broth            tomatoes     butter  skirt steak  black pepper   \n",
       "2      lemons         apple cider     cloves        anise      jalapeno   \n",
       "3  sesame oil  white wine vinegar  soy sauce        sugar   kosher salt   \n",
       "4       cocoa            cupcakes      sugar        flour   baking soda   \n",
       "\n",
       "                  5             6             7                8   \\\n",
       "0  vanilla ice cream                                                \n",
       "1    mashed potatoes        butter          milk  rosemary leaves   \n",
       "2             ginger       bourbon                                  \n",
       "3          asparagus  sesame seeds                                  \n",
       "4    pinch fine salt          beer  stick butter  vanilla extract   \n",
       "\n",
       "             9   ... 53 54 55 56 57 58 59 60 61 62  \n",
       "0                ...                                \n",
       "1  black pepper  ...                                \n",
       "2                ...                                \n",
       "3                ...                                \n",
       "4          eggs  ...                                \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove None values and empty strings\n",
    "df = df.map(lambda x: x if x is not None else '')\n",
    "df = df.map(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 22:14:22 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449aba477f7a4b479d21e2b2f1cde12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 22:14:22 INFO: Downloaded file to /Users/lavo/stanza_resources/resources.json\n",
      "2024-04-30 22:14:22 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-04-30 22:14:22 INFO: Using device: cpu\n",
      "2024-04-30 22:14:22 INFO: Loading: tokenize\n",
      "2024-04-30 22:14:22 INFO: Loading: mwt\n",
      "2024-04-30 22:14:22 INFO: Loading: pos\n",
      "2024-04-30 22:14:22 INFO: Loading: lemma\n",
      "2024-04-30 22:14:23 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize, mwt, pos, lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>butter</td>\n",
       "      <td>brown sugar</td>\n",
       "      <td>banana</td>\n",
       "      <td>bourbon</td>\n",
       "      <td>cinnamon</td>\n",
       "      <td>vanilla ice cream</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beef broth</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>butter</td>\n",
       "      <td>skirt steak</td>\n",
       "      <td>black pepper</td>\n",
       "      <td>mashed potatoes</td>\n",
       "      <td>butter</td>\n",
       "      <td>milk</td>\n",
       "      <td>rosemary leaves</td>\n",
       "      <td>black pepper</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lemons</td>\n",
       "      <td>apple cider</td>\n",
       "      <td>cloves</td>\n",
       "      <td>anise</td>\n",
       "      <td>jalapeno</td>\n",
       "      <td>ginger</td>\n",
       "      <td>bourbon</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sesame oil</td>\n",
       "      <td>white wine vinegar</td>\n",
       "      <td>soy sauce</td>\n",
       "      <td>sugar</td>\n",
       "      <td>kosher salt</td>\n",
       "      <td>asparagus</td>\n",
       "      <td>sesame seeds</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cocoa</td>\n",
       "      <td>cupcakes</td>\n",
       "      <td>sugar</td>\n",
       "      <td>flour</td>\n",
       "      <td>baking soda</td>\n",
       "      <td>pinch fine salt</td>\n",
       "      <td>beer</td>\n",
       "      <td>stick butter</td>\n",
       "      <td>vanilla extract</td>\n",
       "      <td>eggs</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                   1          2            3             4   \\\n",
       "0      butter         brown sugar     banana      bourbon      cinnamon   \n",
       "1  beef broth            tomatoes     butter  skirt steak  black pepper   \n",
       "2      lemons         apple cider     cloves        anise      jalapeno   \n",
       "3  sesame oil  white wine vinegar  soy sauce        sugar   kosher salt   \n",
       "4       cocoa            cupcakes      sugar        flour   baking soda   \n",
       "\n",
       "                  5             6             7                8   \\\n",
       "0  vanilla ice cream                                                \n",
       "1    mashed potatoes        butter          milk  rosemary leaves   \n",
       "2             ginger       bourbon                                  \n",
       "3          asparagus  sesame seeds                                  \n",
       "4    pinch fine salt          beer  stick butter  vanilla extract   \n",
       "\n",
       "             9   ... 53 54 55 56 57 58 59 60 61 62  \n",
       "0                ...                                \n",
       "1  black pepper  ...                                \n",
       "2                ...                                \n",
       "3                ...                                \n",
       "4          eggs  ...                                \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butter',\n",
       " 'brown sugar',\n",
       " 'banana',\n",
       " 'bourbon',\n",
       " 'cinnamon',\n",
       " 'vanilla ice cream',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# convert df to a list of lists\n",
    "ingredients = df.values.tolist()\n",
    "ingredients[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1055/9868 [03:41<30:49,  4.77it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m cleaned_row \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ingredient \u001b[38;5;129;01min\u001b[39;00m row:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Process ingredient through the pipeline\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mingredient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Extract tokenized forms, part-of-speech tags, and lemmatized forms\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [word\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msentences \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent\u001b[38;5;241m.\u001b[39mwords]\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/pipeline/core.py:480\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc, processors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/pipeline/core.py:431\u001b[0m, in \u001b[0;36mPipeline.process\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mget(processor_name):\n\u001b[1;32m    430\u001b[0m         process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mbulk_process \u001b[38;5;28;01mif\u001b[39;00m bulk \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mprocess\n\u001b[0;32m--> 431\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/pipeline/lemma_processor.py:91\u001b[0m, in \u001b[0;36mLemmaProcessor.process\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     89\u001b[0m edits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seq2seq_batch):\n\u001b[0;32m---> 91\u001b[0m     ps, es \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeam_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ps\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m es \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/models/lemma/trainer.py:108\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, batch, beam_size)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    107\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m preds, edit_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m pred_seqs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munmap(ids) \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m preds] \u001b[38;5;66;03m# unmap to tokens\u001b[39;00m\n\u001b[1;32m    110\u001b[0m pred_seqs \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprune_decoded_seqs(pred_seqs)\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/models/common/seq2seq_model.py:257\u001b[0m, in \u001b[0;36mSeq2SeqModel.predict\u001b[0;34m(self, src, src_mask, pos, beam_size, raw)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Predict with beam search. \"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beam_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_greedy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m enc_inputs, batch_size, src_lens, src_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(src, src_mask, pos, raw)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# (1) encode source\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/models/common/seq2seq_model.py:239\u001b[0m, in \u001b[0;36mSeq2SeqModel.predict_greedy\u001b[0;34m(self, src, src_mask, pos, raw)\u001b[0m\n\u001b[1;32m    236\u001b[0m output_seqs \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)]\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m total_done \u001b[38;5;241m<\u001b[39m batch_size \u001b[38;5;129;01mand\u001b[39;00m max_len \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_dec_len:\n\u001b[0;32m--> 239\u001b[0m     log_probs, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m log_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput must have 1-step of output.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m     _, preds \u001b[38;5;241m=\u001b[39m log_probs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/models/common/seq2seq_model.py:136\u001b[0m, in \u001b[0;36mSeq2SeqModel.decode\u001b[0;34m(self, dec_inputs, hn, cn, ctx, ctx_mask, src)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Decode a step, based on context encoding and source context states.\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m dec_hidden \u001b[38;5;241m=\u001b[39m (hn, cn)\n\u001b[0;32m--> 136\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_logattn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[1;32m    138\u001b[0m     h_out, dec_hidden, log_attn \u001b[38;5;241m=\u001b[39m decoder_output\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/stanza/models/common/seq2seq_modules.py:227\u001b[0m, in \u001b[0;36mLSTMAttention.forward\u001b[0;34m(self, input, hidden, ctx, ctx_mask, return_logattn)\u001b[0m\n\u001b[1;32m    225\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[0;32m--> 227\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     hy, cy \u001b[38;5;241m=\u001b[39m hidden\n\u001b[1;32m    229\u001b[0m     h_tilde, alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_layer(hy, ctx, mask\u001b[38;5;241m=\u001b[39mctx_mask, return_logattn\u001b[38;5;241m=\u001b[39mreturn_logattn)\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1346\u001b[0m, in \u001b[0;36mLSTMCell.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched \u001b[38;5;28;01melse\u001b[39;00m hx\n\u001b[0;32m-> 1346\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_cell\u001b[49m(\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28minput\u001b[39m, hx,\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_ih, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_hh,\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_ih, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_hh,\n\u001b[1;32m   1350\u001b[0m )\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[1;32m   1353\u001b[0m     ret \u001b[38;5;241m=\u001b[39m (ret[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), ret[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/torch/_VF.py:26\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf, attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ingredients_l = df.values.tolist()\n",
    "\n",
    "cleaned_ingredients = []\n",
    "\n",
    "with tqdm(total=len(df)) as pbar:\n",
    "    for row in ingredients_l:\n",
    "        cleaned_row = []\n",
    "        for ingredient in row:\n",
    "            # Process ingredient through the pipeline\n",
    "            doc = nlp(ingredient)\n",
    "            \n",
    "            # Extract tokenized forms, part-of-speech tags, and lemmatized forms\n",
    "            tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "            pos_tags = [word.upos for sent in doc.sentences for word in sent.words]\n",
    "            lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "            \n",
    "            ### NOTICE THAT WE ARE USING `lemmas` INSTEAD OF `tokens`, so we will define our clean dictionary with the pure form of the words (their lemmatization!!!) ###\n",
    "            # eliminate the tokens in `tokens` that are ADJ in `pos_tags`\n",
    "            tokens = [lemmas[i] for i in range(len(tokens)) if pos_tags[i] != 'ADJ' and pos_tags[i] != 'PROPN']\n",
    "\n",
    "            # reconvert tokens to a string\n",
    "            cleaned_ingredient = ' '.join(tokens)\n",
    "\n",
    "            # append to the list\n",
    "            cleaned_row.append(cleaned_ingredient)\n",
    "\n",
    "        cleaned_ingredients.append(cleaned_row)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: pulire duplicati, vuoti e pensare a come gestire le labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
