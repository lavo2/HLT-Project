{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./dataset/recipes_82k.csv')\n",
    "df = pd.read_csv('./dataset/ner_ingredients_balanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nota: quando scarichi il dataset aggiungi all'inizio ingredient per creare il titolo altrimenti prende una lista di ingredienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinch salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rill grate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dill gherkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ingredients\n",
       "0    mango juice\n",
       "1     Pinch salt\n",
       "2           rout\n",
       "3     rill grate\n",
       "4  dill gherkins"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 21:51:34 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8a7ae592d54c8291b9589bebc9f9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 21:51:34 INFO: Downloaded file to /Users/lavo/stanza_resources/resources.json\n",
      "2024-04-30 21:51:34 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-04-30 21:51:34 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-04-30 21:51:34 INFO: Using device: cpu\n",
      "2024-04-30 21:51:34 INFO: Loading: tokenize\n",
      "2024-04-30 21:51:35 INFO: Loading: mwt\n",
      "2024-04-30 21:51:35 INFO: Loading: pos\n",
      "2024-04-30 21:51:35 INFO: Loading: lemma\n",
      "2024-04-30 21:51:35 INFO: Done loading processors!\n",
      "100%|██████████| 8543/8543 [02:42<00:00, 52.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import clean_vocabulary\n",
    "\n",
    "df2 = clean_vocabulary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pinch salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rill grate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dill gherkin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ingredients\n",
       "0   mango juice\n",
       "1    pinch salt\n",
       "2          rout\n",
       "3    rill grate\n",
       "4  dill gherkin"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column name to `ingredients`\n",
    "df.rename(columns={'red chicory': 'ingredients'}, inplace=True)\n",
    "df.info()\n",
    "# add a new instance to df\n",
    "df = df._append({'ingredients': 'red chicory'}, ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We strt processingt his dtaaframe: eliminate words of 2 chars, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    # if you encounter a - or ' (or something else) in the text, replace it with a space\n",
    "    #TODO: right?\n",
    "    s1 = re.sub(r'[^a-z\\s]', ' ', s)\n",
    "    s1 = ' '.join([w for w in s1.split() if len(w) > 2])\n",
    "    # remove multiple spaces and starting and ending spaces\n",
    "    s2 = re.sub(r'\\s+', ' ', s1).strip()\n",
    "    return s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ingredients'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# apply the function to the ingredients column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mingredients\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mingredients\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(clean_text)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/Projects/HLT-Project/.venv/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ingredients'"
     ]
    }
   ],
   "source": [
    "# apply the function to the ingredients column\n",
    "df['ingredients'] = df['ingredients'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 1)\n"
     ]
    }
   ],
   "source": [
    "# count empty strings\n",
    "print(df[df['ingredients'] == ''].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 1)\n"
     ]
    }
   ],
   "source": [
    "# duplicates\n",
    "print(df[df.duplicated()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9868, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8580, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate both empty strings and duplicates\n",
    "df = df.drop_duplicates()\n",
    "df = df[df['ingredients'] != '']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 21:26:30 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110edb2149f844f2abb9553908b0ea56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 21:26:30 INFO: Downloaded file to /Users/irene/stanza_resources/resources.json\n",
      "2024-04-29 21:26:30 WARNING: Language en package default expects mwt, which has been added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d44a99824a40629440a55a0754f565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/tokenize/combined.pt:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5023ecdbc64c4a73aaf126113ccfaf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/mwt/combined.pt:   0%|         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d86cdf077724f3299857bc064a7e310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pos/combined_charlm.pt:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115104a67bf243e1ab0d2f974aa477d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/lemma/combined_nocharlm.pt:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef175adb89d411eba99ad96ce329a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/forward_charlm/1billion.pt:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fdf26a69814f46afad4a8ca0f2113c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/backward_charlm/1billion.pt:   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c2d4a3ea4a46fe8521889090a1a351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pretrain/conll17.pt:   0%|     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 21:27:15 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-04-29 21:27:15 INFO: Using device: cpu\n",
      "2024-04-29 21:27:15 INFO: Loading: tokenize\n",
      "2024-04-29 21:27:15 INFO: Loading: mwt\n",
      "2024-04-29 21:27:15 INFO: Loading: pos\n",
      "2024-04-29 21:27:16 INFO: Loading: lemma\n",
      "2024-04-29 21:27:16 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stanza.pipeline.core.Pipeline at 0x31f231ad0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize, pos, lemma')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how these tools work!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Ingredient: bones fish bones\n",
      "Tokens: ['bones', 'fish', 'bones']\n",
      "POS Tags: ['NOUN', 'NOUN', 'NOUN']\n",
      "Lemmas: ['bone', 'fish', 'bone']\n",
      "\n",
      "Original Ingredient: eyed peas\n",
      "Tokens: ['eyed', 'peas']\n",
      "POS Tags: ['ADJ', 'NOUN']\n",
      "Lemmas: ['eye', 'peas']\n",
      "\n",
      "Original Ingredient: sliced pepperoni\n",
      "Tokens: ['sliced', 'pepperoni']\n",
      "POS Tags: ['VERB', 'NOUN']\n",
      "Lemmas: ['slice', 'pepperoni']\n",
      "\n",
      "Original Ingredient: carrot fronds\n",
      "Tokens: ['carrot', 'fronds']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['carrot', 'frond']\n",
      "\n",
      "Original Ingredient: chocolate sprinkles\n",
      "Tokens: ['chocolate', 'sprinkles']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['chocolate', 'sprinkle']\n",
      "\n",
      "Original Ingredient: lash milk\n",
      "Tokens: ['lash', 'milk']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lash', 'milk']\n",
      "\n",
      "Original Ingredient: goose\n",
      "Tokens: ['goose']\n",
      "POS Tags: ['NOUN']\n",
      "Lemmas: ['goose']\n",
      "\n",
      "Original Ingredient: bucatini pasta\n",
      "Tokens: ['bucatini', 'pasta']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['bucatini', 'pasta']\n",
      "\n",
      "Original Ingredient: lowfat yogurt\n",
      "Tokens: ['lowfat', 'yogurt']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lowfat', 'yogurt']\n",
      "\n",
      "Original Ingredient: russet potato\n",
      "Tokens: ['russet', 'potato']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['russet', 'potato']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each ingredient\n",
    "for ingredient in df[7000:7010]['ingredients']:\n",
    "    # Process ingredient through the pipeline\n",
    "    doc = nlp(ingredient)\n",
    "    \n",
    "    # Extract tokenized forms, part-of-speech tags, and lemmatized forms\n",
    "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    pos_tags = [word.upos for sent in doc.sentences for word in sent.words]\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    \n",
    "    # Print the processed information\n",
    "    print(\"Original Ingredient:\", ingredient)\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "    print(\"Lemmas:\", lemmas)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Ingredient: bones fish bones\n",
      "Tokens: ['bone', 'fish', 'bone']\n",
      "POS Tags: ['NOUN', 'NOUN', 'NOUN']\n",
      "Lemmas: ['bone', 'fish', 'bone']\n",
      "\n",
      "Original Ingredient: eyed peas\n",
      "Tokens: ['peas']\n",
      "POS Tags: ['ADJ', 'NOUN']\n",
      "Lemmas: ['eye', 'peas']\n",
      "\n",
      "Original Ingredient: sliced pepperoni\n",
      "Tokens: ['slice', 'pepperoni']\n",
      "POS Tags: ['VERB', 'NOUN']\n",
      "Lemmas: ['slice', 'pepperoni']\n",
      "\n",
      "Original Ingredient: carrot fronds\n",
      "Tokens: ['carrot', 'frond']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['carrot', 'frond']\n",
      "\n",
      "Original Ingredient: chocolate sprinkles\n",
      "Tokens: ['chocolate', 'sprinkle']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['chocolate', 'sprinkle']\n",
      "\n",
      "Original Ingredient: lash milk\n",
      "Tokens: ['lash', 'milk']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lash', 'milk']\n",
      "\n",
      "Original Ingredient: goose\n",
      "Tokens: ['goose']\n",
      "POS Tags: ['NOUN']\n",
      "Lemmas: ['goose']\n",
      "\n",
      "Original Ingredient: bucatini pasta\n",
      "Tokens: ['bucatini', 'pasta']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['bucatini', 'pasta']\n",
      "\n",
      "Original Ingredient: lowfat yogurt\n",
      "Tokens: ['lowfat', 'yogurt']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['lowfat', 'yogurt']\n",
      "\n",
      "Original Ingredient: russet potato\n",
      "Tokens: ['russet', 'potato']\n",
      "POS Tags: ['NOUN', 'NOUN']\n",
      "Lemmas: ['russet', 'potato']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INTERNAL PROCESSING: ELIMINATE ADJ AND PROPN\n",
    "\n",
    "for ingredient in df[7000:7010]['ingredients']:\n",
    "    # Process ingredient through the pipeline\n",
    "    doc = nlp(ingredient)\n",
    "    \n",
    "    # Extract tokenized forms, part-of-speech tags, and lemmatized forms\n",
    "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    pos_tags = [word.upos for sent in doc.sentences for word in sent.words]\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    \n",
    "    ### NOTICE THAT WE ARE USING `lemmas` INSTEAD OF `tokens`, so we will define our clean dictionary with the pure form of the words (their lemmatization!!!) ###\n",
    "    # eliminate the tokens in `tokens` that are ADJ in `pos_tags`\n",
    "    tokens = [lemmas[i] for i in range(len(tokens)) if pos_tags[i] != 'ADJ' and pos_tags[i] != 'PROPN']\n",
    "    \n",
    "    # Print the processed information\n",
    "    print(\"Original Ingredient:\", ingredient)\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "    print(\"Lemmas:\", lemmas)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: valutare se togliere anche VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, now we will have new empty strings!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of new dictionary\n",
    "cleaned_ingredients = []\n",
    "\n",
    "for ingredient in df['ingredients']:\n",
    "    # Process ingredient through the pipeline\n",
    "    doc = nlp(ingredient)\n",
    "    \n",
    "    # Extract tokenized forms, part-of-speech tags, and lemmatized forms\n",
    "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
    "    pos_tags = [word.upos for sent in doc.sentences for word in sent.words]\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    \n",
    "    ### NOTICE THAT WE ARE USING `lemmas` INSTEAD OF `tokens`, so we will define our clean dictionary with the pure form of the words (their lemmatization!!!) ###\n",
    "    # eliminate the tokens in `tokens` that are ADJ in `pos_tags`\n",
    "    tokens = [lemmas[i] for i in range(len(tokens)) if pos_tags[i] != 'ADJ' and pos_tags[i] != 'PROPN']\n",
    "\n",
    "    # reconvert tokens to a string\n",
    "    cleaned_ingredient = ' '.join(tokens)\n",
    "\n",
    "    # append to the list\n",
    "    cleaned_ingredients.append(cleaned_ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pinch salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tooth coriander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vegetable stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ingredients\n",
       "0      mango juice\n",
       "1       pinch salt\n",
       "2  tooth coriander\n",
       "3            stick\n",
       "4  vegetable stock"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch cleaned_ingredients to a DataFrame\n",
    "cleaned_df = pd.DataFrame(cleaned_ingredients, columns=['ingredients'])\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 1)\n"
     ]
    }
   ],
   "source": [
    "# see how many empty strings we have\n",
    "print(cleaned_df[cleaned_df['ingredients'] == ''].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2517, 1)\n"
     ]
    }
   ],
   "source": [
    "# see duplicates\n",
    "print(cleaned_df[cleaned_df.duplicated()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>clam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>plum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>liqueur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>lobster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>plum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>lettuce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>mustard seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ingredients\n",
       "33               \n",
       "42           clam\n",
       "44               \n",
       "60               \n",
       "74               \n",
       "80           rice\n",
       "92               \n",
       "95               \n",
       "105              \n",
       "110              \n",
       "128          plum\n",
       "139        pepper\n",
       "144        potato\n",
       "146         onion\n",
       "151              \n",
       "162              \n",
       "164       liqueur\n",
       "173     chocolate\n",
       "178              \n",
       "187       lobster\n",
       "198        pepper\n",
       "202              \n",
       "225          plum\n",
       "246        pepper\n",
       "257              \n",
       "261              \n",
       "264       lettuce\n",
       "267              \n",
       "304  mustard seed\n",
       "331          rice"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the duplicates \n",
    "cleaned_df[cleaned_df.duplicated()].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6062, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate both empty strings and duplicates\n",
    "cleaned_df = cleaned_df.drop_duplicates()\n",
    "cleaned_df = cleaned_df[cleaned_df['ingredients'] != '']\n",
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ora ingredients !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/ner_recipes_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['butter', 'brown sugar', 'banana', 'bourbon',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['beef broth', 'tomatoes', 'butter', 'skirt st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['lemons', 'apple cider', 'cloves', 'anise', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sesame oil', 'white wine vinegar', 'soy sauc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cocoa', 'cupcakes', 'sugar', 'flour', 'bakin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ingredients\n",
       "0  ['butter', 'brown sugar', 'banana', 'bourbon',...\n",
       "1  ['beef broth', 'tomatoes', 'butter', 'skirt st...\n",
       "2  ['lemons', 'apple cider', 'cloves', 'anise', '...\n",
       "3  ['sesame oil', 'white wine vinegar', 'soy sauc...\n",
       "4  ['cocoa', 'cupcakes', 'sugar', 'flour', 'bakin..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prendo lista degli ingredienti al posto della singola stringa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['butter'\",\n",
       " \" 'brown sugar'\",\n",
       " \" 'banana'\",\n",
       " \" 'bourbon'\",\n",
       " \" 'cinnamon'\",\n",
       " \" 'vanilla ice cream']\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients = []\n",
    "for i in range(len(df)):\n",
    "    ing = (df['ingredients'][i].split(','))\n",
    "    ingredients.append(ing)\n",
    "ingredients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['butter'</td>\n",
       "      <td>'brown sugar'</td>\n",
       "      <td>'banana'</td>\n",
       "      <td>'bourbon'</td>\n",
       "      <td>'cinnamon'</td>\n",
       "      <td>'vanilla ice cream']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['beef broth'</td>\n",
       "      <td>'tomatoes'</td>\n",
       "      <td>'butter'</td>\n",
       "      <td>'skirt steak'</td>\n",
       "      <td>'black pepper'</td>\n",
       "      <td>'mashed potatoes'</td>\n",
       "      <td>'butter'</td>\n",
       "      <td>'milk'</td>\n",
       "      <td>'rosemary leaves'</td>\n",
       "      <td>'black pepper']</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['lemons'</td>\n",
       "      <td>'apple cider'</td>\n",
       "      <td>'cloves'</td>\n",
       "      <td>'anise'</td>\n",
       "      <td>'jalapeno'</td>\n",
       "      <td>'ginger'</td>\n",
       "      <td>'bourbon']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sesame oil'</td>\n",
       "      <td>'white wine vinegar'</td>\n",
       "      <td>'soy sauce'</td>\n",
       "      <td>'sugar'</td>\n",
       "      <td>'Kosher salt'</td>\n",
       "      <td>'asparagus'</td>\n",
       "      <td>'sesame seeds']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cocoa'</td>\n",
       "      <td>'cupcakes'</td>\n",
       "      <td>'sugar'</td>\n",
       "      <td>'flour'</td>\n",
       "      <td>'baking soda'</td>\n",
       "      <td>'Pinch fine salt'</td>\n",
       "      <td>'ut beer'</td>\n",
       "      <td>'stick butter'</td>\n",
       "      <td>'vanilla extract'</td>\n",
       "      <td>'eggs'</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                      1             2               3   \\\n",
       "0      ['butter'          'brown sugar'      'banana'       'bourbon'   \n",
       "1  ['beef broth'             'tomatoes'      'butter'   'skirt steak'   \n",
       "2      ['lemons'          'apple cider'      'cloves'         'anise'   \n",
       "3  ['sesame oil'   'white wine vinegar'   'soy sauce'         'sugar'   \n",
       "4       ['cocoa'             'cupcakes'       'sugar'         'flour'   \n",
       "\n",
       "                4                      5                 6                7   \\\n",
       "0       'cinnamon'   'vanilla ice cream']              None             None   \n",
       "1   'black pepper'      'mashed potatoes'          'butter'           'milk'   \n",
       "2       'jalapeno'               'ginger'        'bourbon']             None   \n",
       "3    'Kosher salt'            'asparagus'   'sesame seeds']             None   \n",
       "4    'baking soda'      'Pinch fine salt'         'ut beer'   'stick butter'   \n",
       "\n",
       "                   8                 9   ...    53    54    55    56    57  \\\n",
       "0                None              None  ...  None  None  None  None  None   \n",
       "1   'rosemary leaves'   'black pepper']  ...  None  None  None  None  None   \n",
       "2                None              None  ...  None  None  None  None  None   \n",
       "3                None              None  ...  None  None  None  None  None   \n",
       "4   'vanilla extract'            'eggs'  ...  None  None  None  None  None   \n",
       "\n",
       "     58    59    60    61    62  \n",
       "0  None  None  None  None  None  \n",
       "1  None  None  None  None  None  \n",
       "2  None  None  None  None  None  \n",
       "3  None  None  None  None  None  \n",
       "4  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ingredients)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sono sudicioni ma la regex dovrebbe pulirli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
